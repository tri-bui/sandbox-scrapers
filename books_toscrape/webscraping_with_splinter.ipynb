{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping with Splinter\n",
    "\n",
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sites to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quotes site url\n",
    "quotes_url = 'https://quotes.toscrape.com/'\n",
    "\n",
    "# Books site url\n",
    "books_url = 'https://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping quotes with requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request to the site\n",
    "response = requests.get(quotes_url)\n",
    "\n",
    "# Parse the html\n",
    "response_soup = soup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten tags\n",
      "============\n",
      "love\n",
      "inspirational\n",
      "life\n",
      "humor\n",
      "books\n",
      "reading\n",
      "friendship\n",
      "friends\n",
      "truth\n",
      "simile\n"
     ]
    }
   ],
   "source": [
    "# \"Top Ten Tags\" title\n",
    "print(response_soup.find('h2').text)\n",
    "print('============')\n",
    "\n",
    "# Top 10 tags\n",
    "tags_box = response_soup.find('div', class_='tags-box')\n",
    "for tag in tags_box.find_all('a', class_='tag'):\n",
    "    print(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes to Scrape\n",
      "================\n",
      "\n",
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "----- Albert Einstein\n",
      "\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "----- J.K. Rowling\n",
      "\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "----- Albert Einstein\n",
      "\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "----- Jane Austen\n",
      "\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "----- Marilyn Monroe\n",
      "\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "----- Albert Einstein\n",
      "\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "----- André Gide\n",
      "\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "----- Thomas A. Edison\n",
      "\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "----- Eleanor Roosevelt\n",
      "\n",
      "“A day without sunshine is like, you know, night.”\n",
      "----- Steve Martin\n"
     ]
    }
   ],
   "source": [
    "# \"Quotes to Scrape\" title\n",
    "print(response_soup.find('h1').find('a').text)\n",
    "print('================')\n",
    "\n",
    "# Quotes\n",
    "for quote in response_soup.find_all('div', class_='quote'):\n",
    "    print()\n",
    "    print(quote.find('span', class_='text').text)\n",
    "    print('-----', quote.find('small', class_='author').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize splinter browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\n"
     ]
    }
   ],
   "source": [
    "# Executable path for chromedriver\n",
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create browser instance\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping quotes with splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP QUOTE ON EACH PAGE\n",
      "======================\n",
      "\n",
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "----- Albert Einstein\n",
      "\n",
      "“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\n",
      "----- Marilyn Monroe\n",
      "\n",
      "“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”\n",
      "----- Pablo Neruda\n",
      "\n",
      "“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”\n",
      "----- Pablo Neruda\n",
      "\n",
      "“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”\n",
      "----- Pablo Neruda\n",
      "\n",
      "“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”\n",
      "----- Pablo Neruda\n",
      "\n",
      "“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”\n",
      "----- Pablo Neruda\n",
      "\n",
      "“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”\n",
      "----- Pablo Neruda\n",
      "\n",
      "“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”\n",
      "----- Pablo Neruda\n",
      "\n",
      "“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”\n",
      "----- Pablo Neruda\n"
     ]
    }
   ],
   "source": [
    "# Visit site\n",
    "browser.visit(quotes_url)\n",
    "\n",
    "# \"Quotes to Scrape\" title\n",
    "print('TOP QUOTE ON EACH PAGE')\n",
    "print('======================')\n",
    "\n",
    "# For each page\n",
    "for p in range(1, 11):\n",
    "    \n",
    "    # Get html\n",
    "    page_soup = soup(browser.html, 'html.parser')\n",
    "    \n",
    "    # Get 1st quote on page\n",
    "    quote = page_soup.find('div', class_='quote')\n",
    "    print()\n",
    "    print(quote.find('span', class_='text').text)\n",
    "    print('-----', quote.find('small', class_='author').text)\n",
    "    \n",
    "    # Go to next page\n",
    "    if p != 10:\n",
    "        browser.click_link_by_partial_text('Next')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping books with splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "TOP ROW OF BOOKS IN EACH CATEGORY\n",
      "=================================\n",
      "\n",
      "Travel\n",
      "------------------\n",
      "It's Only the Himalayas ---- £45.17\n",
      "Full Moon over Noah’s ... ---- £49.43\n",
      "See America: A Celebration ... ---- £48.87\n",
      "Vagabonding: An Uncommon Guide ... ---- £36.94\n",
      "\n",
      "Mystery\n",
      "------------------\n",
      "It's Only the Himalayas ---- £45.17\n",
      "Full Moon over Noah’s ... ---- £49.43\n",
      "See America: A Celebration ... ---- £48.87\n",
      "Vagabonding: An Uncommon Guide ... ---- £36.94\n",
      "\n",
      "Historical Fiction\n",
      "------------------\n",
      "It's Only the Himalayas ---- £45.17\n",
      "Full Moon over Noah’s ... ---- £49.43\n",
      "See America: A Celebration ... ---- £48.87\n",
      "Vagabonding: An Uncommon Guide ... ---- £36.94\n",
      "\n",
      "Sequential Art\n",
      "------------------\n",
      "It's Only the Himalayas ---- £45.17\n",
      "Full Moon over Noah’s ... ---- £49.43\n",
      "See America: A Celebration ... ---- £48.87\n",
      "Vagabonding: An Uncommon Guide ... ---- £36.94\n",
      "\n",
      "Classics\n",
      "------------------\n",
      "It's Only the Himalayas ---- £45.17\n",
      "Full Moon over Noah’s ... ---- £49.43\n",
      "See America: A Celebration ... ---- £48.87\n",
      "Vagabonding: An Uncommon Guide ... ---- £36.94\n"
     ]
    }
   ],
   "source": [
    "# Get site html\n",
    "browser.visit(books_url)\n",
    "book_soup = soup(browser.html, 'html.parser')\n",
    "\n",
    "# Title\n",
    "print('=================================')\n",
    "print('TOP ROW OF BOOKS IN EACH CATEGORY')\n",
    "print('=================================')\n",
    "\n",
    "# Category href\n",
    "cat_href = 'catalogue/category/books/'\n",
    "href_start = lambda href: href.startswith(cat_href)\n",
    "\n",
    "# Category list\n",
    "categories = book_soup.find('div', class_='side_categories')\n",
    "categories = categories.find_all('a', href=href_start)\n",
    "categories = [cat.text.strip() for cat in categories]\n",
    "\n",
    "# For each category\n",
    "for cat in categories[:5]: # Limit to top 5 categories\n",
    "    \n",
    "    # Click category and get html\n",
    "    browser.click_link_by_partial_text(cat)\n",
    "    cat_soup = soup(browser.html, 'html.parser')\n",
    "    \n",
    "    # Category name\n",
    "    print()\n",
    "    print(cat)\n",
    "    print('------------------')\n",
    "    \n",
    "    # Get top row of books\n",
    "    for book in cat_soup.find_all('article', class_='product_pod')[:4]:\n",
    "        title = book.find('h3').find('a').text\n",
    "        price = book.find('p', class_='price_color').text\n",
    "        print(f'{title} ---- {price}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book scraping script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "\n",
    "# Initialize a browser\n",
    "exe_path = '/usr/local/bin/chromedriver'\n",
    "browser = Browser('chrome', executable_path=exe_path, headless=False)\n",
    "\n",
    "# Visit the site and get the html\n",
    "site_url = 'https://books.toscrape.com/'\n",
    "site_url = 'https://books.toscrape.com/catalogue/category/books/mystery_3/index.html'\n",
    "browser.visit(site_url)\n",
    "book_soup = Soup(browser.html, 'html.parser')\n",
    "\n",
    "# Book data\n",
    "headings = 'upc,title,category,price,rating,num_reviews'\n",
    "headings += ',in_stock,num_available,url\\n'\n",
    "book_data = [headings]\n",
    "\n",
    "# Output file\n",
    "outfile = 'book_data.csv'\n",
    "with open(outfile, 'a') as f:\n",
    "    f.write(headings)\n",
    "\n",
    "# Book count\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue scraping for all pages\n",
    "while True:\n",
    "\n",
    "    # Get a list of book titles on the page\n",
    "    book_soup = Soup(browser.html, 'html.parser')\n",
    "    books = book_soup.find_all('article', class_='product_pod')\n",
    "    titles = [book.find('h3').find('a').text for book in books]\n",
    "    \n",
    "    # For each book on the page\n",
    "    for t in titles:\n",
    "\n",
    "        i += 1\n",
    "        print(i, t)\n",
    "\n",
    "        # Initialize data variables\n",
    "        upc = title = category = price = rating = num_reviews = ''\n",
    "        in_stock = num_available = url = '' \n",
    "\n",
    "        # Go to the book's page and get the html\n",
    "        try:\n",
    "            browser.click_link_by_partial_text(t)\n",
    "            url = browser.url\n",
    "            page_soup = Soup(browser.html, 'html.parser')\n",
    "        except:\n",
    "            print(' - Not found:', t)\n",
    "            continue\n",
    "\n",
    "        # Breadcrumb\n",
    "        try:\n",
    "            crumb = page_soup.find('ul', class_='breadcrumb').find_all('li')\n",
    "            category = crumb[2].find('a').text\n",
    "        except:\n",
    "            print(' - Category missing')\n",
    "\n",
    "        # Main product section\n",
    "        try:\n",
    "            p_main = page_soup.find('div', class_='product_main')\n",
    "            title = p_main.find('h1').text\n",
    "            price = p_main.find('p', class_='price_color').text[1:]\n",
    "            rating = p_main.find('p', class_='star-rating').attrs['class'][1]\n",
    "        except:\n",
    "            print(' - Title/price/rating missing')\n",
    "\n",
    "        # Stock availability\n",
    "        try:\n",
    "            stock = p_main.find('p', class_='availability').text.strip()\n",
    "            stock = stock.split('(')\n",
    "            in_stock = stock[0].strip()\n",
    "            num_available = stock[1].split()[0]\n",
    "        except:\n",
    "            print(' - Stock/availability missing')\n",
    "\n",
    "        # Product information\n",
    "        try:\n",
    "            p_info = page_soup.find('table')\n",
    "            upc = p_info.find('td').text\n",
    "            num_reviews = p_info.find_all('td')[-1].text\n",
    "        except:\n",
    "            print(' - UPC/reviews missing')\n",
    "\n",
    "        # Click back\n",
    "        if re.search(r'/page\\-\\d+\\.', url):\n",
    "            continue\n",
    "        else:\n",
    "            browser.back()\n",
    "\n",
    "        # Add book to data\n",
    "        book = f'{upc};{title};{category};{price};{rating};{num_reviews}'\n",
    "        book += f';{in_stock};{num_available};{url}\\n'\n",
    "        book_data.append(book)\n",
    "\n",
    "        # Write row to file\n",
    "        with open(outfile, 'a') as f:\n",
    "            f.write(book)\n",
    "\n",
    "    # Go to next page\n",
    "    try:\n",
    "        browser.click_link_by_partial_text('next')\n",
    "    except:\n",
    "        break\n",
    "\n",
    "\n",
    "# # Write data to file\n",
    "# f = open(outfile, 'a')\n",
    "# for book in book_data:\n",
    "#     f.write(book)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
